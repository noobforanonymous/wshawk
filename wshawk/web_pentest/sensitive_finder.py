"""
WSHawk Sensitive Data Finder
Scans HTTP responses for leaked secrets: API keys, tokens, internal IPs,
email addresses, AWS credentials, private keys, and other sensitive patterns.
"""

import aiohttp
import asyncio
import re
from typing import Dict, List, Any

# Regex patterns for sensitive data detection
PATTERNS = {
    "AWS Access Key": r"(?:AKIA|A3T[A-Z0-9])[A-Z0-9]{16}",
    "AWS Secret Key": r"(?i)aws[_\-]?secret[_\-]?access[_\-]?key[\s=:\"']+([A-Za-z0-9/+=]{40})",
    "Google API Key": r"AIza[0-9A-Za-z\-_]{35}",
    "GitHub Token": r"gh[ps]_[A-Za-z0-9_]{36,255}",
    "Slack Token": r"xox[baprs]-[0-9]{10,13}-[0-9]{10,13}-[a-zA-Z0-9]{24,34}",
    "Stripe Secret Key": r"sk_live_[0-9a-zA-Z]{24,99}",
    "Stripe Publishable Key": r"pk_live_[0-9a-zA-Z]{24,99}",
    "Mailgun API Key": r"key-[0-9a-zA-Z]{32}",
    "Twilio API Key": r"SK[0-9a-fA-F]{32}",
    "Square OAuth Secret": r"sq0csp-[0-9A-Za-z\-_]{43}",
    "JWT Token": r"eyJ[A-Za-z0-9_-]{10,}\.eyJ[A-Za-z0-9_-]{10,}\.[A-Za-z0-9_-]{10,}",
    "Private Key Header": r"-----BEGIN (?:RSA |EC |DSA |OPENSSH )?PRIVATE KEY-----",
    "Internal IPv4": r"\b(?:10\.\d{1,3}\.\d{1,3}\.\d{1,3}|172\.(?:1[6-9]|2\d|3[0-1])\.\d{1,3}\.\d{1,3}|192\.168\.\d{1,3}\.\d{1,3})\b",
    "Email Address": r"[a-zA-Z0-9._%+\-]+@[a-zA-Z0-9.\-]+\.[a-zA-Z]{2,}",
    "Authorization Header": r"(?i)(?:authorization|bearer|token)[\s:=]+['\"]?[A-Za-z0-9\-._~+/]+=*['\"]?",
    "Database Connection String": r"(?:mysql|postgres|mongodb|redis|sqlite)://[^\s\"'<>]+",
    "Firebase URL": r"https://[a-z0-9\-]+\.firebaseio\.com",
    "Heroku API Key": r"(?i)heroku[_\-]?api[_\-]?key[\s=:\"']+([0-9a-fA-F\-]{36})",
    "S3 Bucket URL": r"https?://[a-zA-Z0-9.\-]+\.s3[.\-]?[a-zA-Z0-9\-]*\.amazonaws\.com",
    "Password in URL": r"(?i)[?&](?:pass(?:word)?|pwd|secret|key|token)=[^&\s]{3,}",
}


class WSHawkSensitiveFinder:
    """Scans web pages for leaked sensitive data patterns."""

    def __init__(self, sio_instance=None):
        self.sio = sio_instance

    async def scan_url(self, url: str) -> Dict[str, Any]:
        """Scan a single URL for sensitive data leaks."""
        if not url:
            raise ValueError("URL required")

        url = url.strip()
        if not url.startswith(("http://", "https://")):
            url = "https://" + url

        findings: List[Dict] = []

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, ssl=False, allow_redirects=True,
                                       timeout=aiohttp.ClientTimeout(total=10)) as resp:
                    body = await resp.text(errors='ignore')
                    # Also check response headers as a string
                    headers_str = "\n".join([f"{k}: {v}" for k, v in resp.headers.items()])
        except Exception as e:
            return {
                "url": url,
                "findings": [],
                "total": 0,
                "error": f"Request failed: {str(e)}"
            }

        full_text = body + "\n" + headers_str

        for pattern_name, regex in PATTERNS.items():
            try:
                matches = re.findall(regex, full_text)
            except re.error:
                continue

            if matches:
                # Deduplicate
                unique_matches = list(set(matches))[:5]  # Cap at 5 per pattern to avoid noise
                for match in unique_matches:
                    # Mask sensitive parts for safe display
                    display_val = _mask_value(str(match))
                    severity = _severity_for(pattern_name)

                    findings.append({
                        "type": pattern_name,
                        "severity": severity,
                        "value": display_val,
                        "raw_length": len(str(match)),
                        "url": url
                    })

        return {
            "url": url,
            "findings": findings,
            "total": len(findings)
        }

    async def scan_urls(self, urls: List[str]) -> Dict[str, Any]:
        """Scan multiple URLs concurrently for sensitive data."""
        sem = asyncio.Semaphore(5)
        all_findings = []

        async def _scan(u: str):
            async with sem:
                try:
                    result = await self.scan_url(u)
                    all_findings.extend(result.get("findings", []))
                    if self.sio and result.get("findings"):
                        await self.sio.emit("sensitive_found", {
                            "url": u,
                            "count": len(result["findings"])
                        })
                except Exception:
                    pass

        await asyncio.gather(*[_scan(u) for u in urls])

        return {
            "urls_scanned": len(urls),
            "findings": all_findings,
            "total": len(all_findings)
        }


def _mask_value(val: str) -> str:
    """Partially mask sensitive values for safe display."""
    if len(val) <= 8:
        return val[:2] + "***"
    return val[:4] + "****" + val[-4:]


def _severity_for(pattern_name: str) -> str:
    """Assign severity based on the type of leaked data."""
    high = {
        "AWS Access Key", "AWS Secret Key", "GitHub Token", "Stripe Secret Key",
        "Slack Token", "Private Key Header", "Database Connection String",
        "Heroku API Key", "Authorization Header"
    }
    medium = {
        "Google API Key", "JWT Token", "Firebase URL", "S3 Bucket URL",
        "Password in URL", "Mailgun API Key", "Twilio API Key", "Square OAuth Secret",
        "Stripe Publishable Key"
    }
    # Everything else is Low
    if pattern_name in high:
        return "High"
    elif pattern_name in medium:
        return "Medium"
    return "Low"

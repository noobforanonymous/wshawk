"""
WSHawk Web Fuzzer Engine
Sends parameterized HTTP requests with wordlists, payload encoding,
and regex-based response matching (grep). Supports custom wordlists
loaded from disk and multiple encoding formats.
"""

import aiohttp
import asyncio
import time
import os
import re
import base64
import urllib.parse
from typing import Any, List, Dict, Optional


class WSHawkFuzzer:
    """
    HTTP fuzzer that replaces §FUZZ§ markers in URLs with wordlist entries.

    Features:
        - Built-in wordlists (common, sqli, xss)
        - Custom wordlist loading from disk
        - Payload encoding (base64, url, hex)
        - Regex grep matching on response bodies
        - Concurrent requests with semaphore throttling
    """

    # Built-in wordlists for quick use
    DEFAULT_WORDLISTS = {
        "common": [
            "admin", "login", "test", "api", "css", "js", ".git",
            "backup", "db", "config", "v1", "v2", "dashboard", "panel",
            "upload", "static", "assets", "images", "debug", "status",
        ],
        "sqli": [
            "'", "''", "`", "admin' --", "' OR 1=1--", "1' OR '1'='1",
            "%27", "WAITFOR DELAY '0:0:5'", "1;SELECT SLEEP(5)--",
            "' UNION SELECT NULL--", "' AND 1=CONVERT(int,(SELECT @@version))--",
        ],
        "xss": [
            "<script>alert(1)</script>", "\"><svg/onload=alert(1)>",
            "javascript:alert(1)", "<img src=x onerror=alert(1)>",
            "'><script>alert(document.cookie)</script>",
        ],
    }

    # Max wordlist size to prevent memory issues
    MAX_WORDLIST_SIZE = 50000

    def __init__(self, sio_instance=None):
        self.sio = sio_instance

    def _encode_payload(self, payload: str, encoder: str) -> str:
        """Apply encoding transform to a payload string."""
        if encoder == "base64":
            return base64.b64encode(payload.encode()).decode()
        elif encoder == "url":
            return urllib.parse.quote_plus(payload)
        elif encoder == "hex":
            return payload.encode().hex()
        elif encoder == "json":
            import json
            return json.dumps(payload)[1:-1] # Strip the surrounding quotes added by json.dumps
        return payload

    async def run_fuzz(
        self,
        method: str,
        url: str,
        wordlist_name: str,
        custom_file: Optional[str] = None,
        encoder: str = "none",
        grep_regex: str = "",
        attack_type: str = "sniper",
        body: str = "",
        headers: Optional[Dict[str, str]] = None,
        cookies: Optional[Dict[str, str]] = None,
    ) -> int:
        """
        Run an HTTP fuzzing task against a URL/body/headers with §FUZZ§ markers.

        Args:
            method:        HTTP method (GET, POST, etc.).
            url:           Target URL containing §FUZZ§ placeholder(s).
            wordlist_name: Name of built-in wordlist ('common', 'sqli', 'xss').
            custom_file:   Path to a custom wordlist file on disk (optional).
            encoder:       Encoding to apply ('none', 'base64', 'url', 'hex').
            grep_regex:    Regex pattern to match against response bodies.
            attack_type:   Attack mode — currently 'sniper' (single marker).
            body:          Optional HTTP request body containing §FUZZ§ placeholder(s).
            headers:       Optional Dict of headers. Values can contain §FUZZ§.
            cookies:       Optional Dict of session cookies to send.

        Returns:
            Number of payloads fuzzed.

        Raises:
            ValueError: If URL is empty or missing the §FUZZ§ marker.
        """
        # ── Input validation ──
        headers_str = str(headers) if headers else ""
        if not url or ("§FUZZ§" not in url and "§FUZZ§" not in body and "§FUZZ§" not in headers_str):
            raise ValueError("Target must contain at least one §FUZZ§ marker in URL, Body, or Headers")

        method = method.strip().upper()

        # ── Load wordlist ──
        wordlist = self._load_wordlist(wordlist_name, custom_file)
        if not wordlist:
            raise ValueError("Wordlist is empty — nothing to fuzz")

        # ── Compile grep regex ──
        compiled_regex = None
        if grep_regex:
            try:
                compiled_regex = re.compile(grep_regex, re.IGNORECASE)
            except re.error:
                pass  # Invalid regex is silently ignored

        # ── Baseline Request (Auth Bypass heuristic) ──
        baseline_length = 0
        baseline_cookies = set()
        baseline_status = 404
        baseline_time = 0.1
        try:
            b_payload = "wshpk_invalid_baseline_1337"
            b_url = url.replace("§FUZZ§", b_payload)
            b_body = body.replace("§FUZZ§", b_payload) if body else None
            b_hdrs = {k: v.replace("§FUZZ§", b_payload) for k, v in headers.items()} if headers else None

            async with aiohttp.ClientSession(cookies=cookies) as session:
                b_start = time.time()
                async with session.request(
                    method, b_url, data=b_body, headers=b_hdrs,
                    ssl=False, allow_redirects=False, timeout=aiohttp.ClientTimeout(total=5)
                ) as b_resp:
                    b_bytes = await b_resp.read()
                    baseline_length = len(b_bytes)
                    baseline_status = b_resp.status
                    baseline_cookies = set(c.key for c in b_resp.cookies.values())
                    baseline_time = time.time() - b_start
        except Exception:
            pass # Baseline failed silently, heuristics will just be less accurate

        # ── Fuzz loop ──
        sem = asyncio.Semaphore(15)

        findings = []

        async def _fuzz_one(raw_payload: str):
            async with sem:
                # Replace __TIME__ placeholder with 5 seconds for sleep payloads
                if "__TIME__" in raw_payload:
                    raw_payload = raw_payload.replace("__TIME__", "5")
                
                payload = self._encode_payload(raw_payload, encoder)
                target_url = url.replace("§FUZZ§", payload)
                target_body = body.replace("§FUZZ§", payload) if body else None
                
                target_headers = None
                if headers:
                    target_headers = {k: v.replace("§FUZZ§", payload) for k, v in headers.items()}
                
                start_t = time.time()

                try:
                    timeout = aiohttp.ClientTimeout(total=8)
                    async with aiohttp.ClientSession(cookies=cookies) as session:
                        async with session.request(
                            method, target_url,
                            data=target_body,
                            headers=target_headers,
                            ssl=False,
                            allow_redirects=False,
                            timeout=timeout,
                        ) as resp:
                            resp_body = await resp.read()
                            body_text = resp_body.decode(errors='ignore')
                            time_taken = time.time() - start_t

                            grep_match = bool(
                                compiled_regex and compiled_regex.search(body_text)
                            )
                            
                            # Heuristics
                            auth_bypass = False
                            resp_len = len(resp_body)
                            
                            if (resp.status in [301, 302, 303, 307] and baseline_status not in [301, 302, 303, 307] and "login" not in resp.headers.get("Location", "").lower()):
                                auth_bypass = True
                            
                            new_cookies = set(c.key for c in resp.cookies.values())
                            if new_cookies - baseline_cookies:
                                auth_bypass = True

                            if abs(resp_len - baseline_length) > 500:
                                auth_bypass = True

                            # Time-based blind SQLi (e.g. pg_sleep(5), WAITFOR DELAY '0:0:5')
                            # If it took more than 3 seconds longer than the baseline, likely time-based.
                            time_match = time_taken > (baseline_time + 4.0)
                            
                            # XSS Reflection
                            xss_reflection = payload in body_text if ("<" in payload or ">" in payload or "javascript:" in payload.lower()) else False
                            
                            # LFI/Path Traversal
                            # Windows: [boot loader], root:x:0:0
                            lfi_match = "root:x:0:0:" in body_text or "[boot loader]" in body_text or "Volume Serial Number" in body_text or "mail:x:8:" in body_text
                            
                            # Command Injection
                            # Check for typical id, whoami, ipconfig output
                            cmd_match = ("uid=" in body_text and "gid=" in body_text and "groups=" in body_text) or "Windows IP Configuration" in body_text or "Linux version" in body_text
                            
                            result_data = {
                                "payload": payload,
                                "status": resp.status,
                                "length": resp_len,
                                "time": f"{int(time_taken * 1000)}ms",
                                "grepped": grep_match,
                                "auth_bypass": auth_bypass,
                                "time_match": time_match,
                                "xss": xss_reflection,
                                "lfi": lfi_match,
                                "cmd": cmd_match
                            }
                            
                            if grep_match or auth_bypass or time_match or xss_reflection or lfi_match or cmd_match:
                                findings.append(result_data)

                            if self.sio:
                                await self.sio.emit("fuzz_result", result_data)
                except asyncio.TimeoutError:
                    if self.sio:
                        await self.sio.emit("fuzz_result", {
                            "payload": payload,
                            "status": 0,
                            "length": 0,
                            "time": "TIMEOUT",
                            "grepped": False,
                        })
                except Exception:
                    pass  # Connection errors are expected during fuzzing

        await asyncio.gather(*[_fuzz_one(p) for p in wordlist])

        if self.sio:
            await self.sio.emit("fuzz_done", {})

        return {"count": len(wordlist), "findings": findings}

    def _load_wordlist(self, name: str, custom_file: Optional[str]) -> List[str]:
        """Load a wordlist from disk or use a built-in one."""
        if custom_file and custom_file.strip():
            path = custom_file.strip()
            if os.path.isfile(path):
                try:
                    with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                        lines = [
                            line.strip() for line in f
                            if line.strip() and not line.startswith('#')
                        ]
                    return lines[:self.MAX_WORDLIST_SIZE]
                except Exception:
                    return []

        # Map shorthand names
        file_map = {
            "sqli": "sql_injection.txt",
            "xss": "xss.txt",
            "open_redirect": "open_redirect.txt",
            "path_traversal": "path_traversal.txt",
            "lfi": "path_traversal.txt",
            "cmd": "command_injection.txt",
        }

        filename = file_map.get(name.lower(), f"{name.lower()}_injection.txt" if "injection" not in name.lower() else f"{name.lower()}.txt")
        payloads_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "payloads")
        potential_path = os.path.join(payloads_dir, filename)

        if not os.path.isfile(potential_path) and os.path.isfile(os.path.join(payloads_dir, f"{name.lower()}.txt")):
            potential_path = os.path.join(payloads_dir, f"{name.lower()}.txt")

        if os.path.isfile(potential_path):
            try:
                with open(potential_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = [
                        line.strip() for line in f
                        if line.strip() and not line.startswith('#')
                    ]
                if lines:
                    return lines[:self.MAX_WORDLIST_SIZE]
            except Exception:
                pass

        return list(self.DEFAULT_WORDLISTS.get(
            name.lower(), self.DEFAULT_WORDLISTS["common"]
        ))
